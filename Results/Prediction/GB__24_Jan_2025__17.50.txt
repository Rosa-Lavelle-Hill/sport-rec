GB:
Training done. Time taken: 2 days, 13:12:34.531709
params tried:
{'estimator__classifier__min_samples_split': [2, 4, 6], 'estimator__classifier__max_depth': [5, 10], 'estimator__classifier__n_estimators': [500, 800], 'estimator__classifier__random_state': [93], 'estimator__classifier__max_features': [0.7, None], 'estimator__oversampler__k_neighbors': [3, 5], 'estimator__oversampler__sampling_strategy': ['auto']}

Best training make_scorer(f1_score, response_method='predict', average=micro, zero_division=0) score: 0.435. Best model params:
{'estimator__classifier__learning_rate': 0.01, 'estimator__classifier__max_depth': 5, 'estimator__classifier__max_features': None, 'estimator__classifier__min_samples_leaf': 2, 'estimator__classifier__n_estimators': 800, 'estimator__classifier__random_state': 93, 'estimator__classifier__subsample': 0.8, 'estimator__oversampler__k_neighbors': 5, 'estimator__oversampler__sampling_strategy': 'auto'}.

Best GB model performance on test data:
              precision    recall  f1-score   support

           0       0.62      0.63      0.63      2117
           1       0.33      0.46      0.39       847
           2       0.17      0.23      0.19       450
           3       0.55      0.59      0.57      1653
           4       0.22      0.47      0.30       501
           5       0.19      0.38      0.25       290
           6       0.28      0.59      0.38       617
           7       0.25      0.38      0.30       458
           8       0.40      0.63      0.49       466
           9       0.23      0.35      0.28       398

   micro avg       0.38      0.53      0.45      7797
   macro avg       0.32      0.47      0.38      7797
weighted avg       0.42      0.53      0.46      7797
 samples avg       0.38      0.53      0.41      7797

Confusion matrices:
 Predicted: 
   N | P  
[[TN, FP] 
[FN, TP]] 
 
[[[1191  815]
  [ 777 1340]]

 [[2502  774]
  [ 460  387]]

 [[3149  524]
  [ 346  104]]

 [[1662  808]
  [ 673  980]]

 [[2757  865]
  [ 264  237]]

 [[3359  474]
  [ 179  111]]

 [[2587  919]
  [ 251  366]]

 [[3126  539]
  [ 283  175]]

 [[3223  434]
  [ 174  292]]

 [[3258  467]
  [ 260  138]]]
