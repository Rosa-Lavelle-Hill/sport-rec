Enet:
Training done. Time taken: 0:05:15.539391
params tried:
{'estimator__classifier__max_depth': [10, 12, 15, 17], 'estimator__classifier__max_features': [0.7, 0.85, 0.9, 1], 'estimator__classifier__min_samples_split': [2, 3, 4], 'estimator__classifier__n_estimators': [800], 'estimator__classifier__random_state': [93], 'estimator__oversampler__k_neighbors': [3, 5, 7], 'estimator__oversampler__sampling_strategy': ['auto']}

Best training make_scorer(f1_score, response_method='predict', average=micro, zero_division=0) score: 0.407. Best model params:
{'estimator__classifier__C': 1, 'estimator__classifier__l1_ratio': 0.2, 'estimator__classifier__max_iter': 1000, 'estimator__oversampler__k_neighbors': 7, 'estimator__oversampler__sampling_strategy': 'auto'}.

Best Enet model performance on test data:
              precision    recall  f1-score   support

           0       0.62      0.63      0.62      2117
           1       0.28      0.62      0.38       847
           2       0.12      0.56      0.20       450
           3       0.52      0.64      0.57      1653
           4       0.19      0.74      0.30       501
           5       0.15      0.67      0.24       290
           6       0.26      0.74      0.39       617
           7       0.18      0.69      0.28       458
           8       0.33      0.77      0.47       466
           9       0.19      0.65      0.29       398

   micro avg       0.29      0.66      0.41      7797
   macro avg       0.28      0.67      0.37      7797
weighted avg       0.39      0.66      0.46      7797
 samples avg       0.30      0.66      0.39      7797

Confusion matrices:
 Predicted: 
   N | P  
[[TN, FP] 
[FN, TP]] 
 
[[[1187  819]
  [ 785 1332]]

 [[1914 1362]
  [ 322  525]]

 [[1890 1783]
  [ 198  252]]

 [[1472  998]
  [ 588 1065]]

 [[1992 1630]
  [ 129  372]]

 [[2695 1138]
  [  97  193]]

 [[2226 1280]
  [ 158  459]]

 [[2186 1479]
  [ 141  317]]

 [[2933  724]
  [ 105  361]]

 [[2595 1130]
  [ 141  257]]]
