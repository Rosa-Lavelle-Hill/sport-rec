GB:
Training done. Time taken: 0:06:39.020929
params tried:
{'ml__estimator__min_samples_split': [2, 4, 6], 'ml__estimator__max_depth': [5, 10, 15], 'ml__estimator__n_estimators': [500], 'ml__estimator__random_state': [93], 'ml__estimator__max_features': [0.8, 1]}

Best training make_scorer(f1_score, response_method='predict', average=micro, zero_division=0) score: 0.371. Best model params:
{'ml__estimator__learning_rate': 1, 'ml__estimator__max_depth': 5, 'ml__estimator__max_iter': 500, 'ml__estimator__min_samples_leaf': 6, 'ml__estimator__random_state': 93}.

Best GB model performance on test data:
              precision    recall  f1-score   support

           0       0.61      0.63      0.62      2117
           1       0.31      0.10      0.15       847
           2       0.15      0.03      0.05       450
           3       0.56      0.41      0.47      1653
           4       0.16      0.03      0.05       501
           5       0.20      0.07      0.10       290
           6       0.22      0.04      0.06       617
           7       0.23      0.08      0.12       458
           8       0.46      0.38      0.42       466
           9       0.21      0.08      0.12       398

   micro avg       0.51      0.31      0.39      7797
   macro avg       0.31      0.18      0.22      7797
weighted avg       0.41      0.31      0.34      7797
 samples avg       0.42      0.32      0.34      7797

Confusion matrices:
 Predicted: 
   N | P  
[[TN, FP] 
[FN, TP]] 
 
[[[1143  863]
  [ 774 1343]]

 [[3087  189]
  [ 761   86]]

 [[3606   67]
  [ 438   12]]

 [[1941  529]
  [ 977  676]]

 [[3543   79]
  [ 486   15]]

 [[3755   78]
  [ 270   20]]

 [[3423   83]
  [ 594   23]]

 [[3545  120]
  [ 422   36]]

 [[3451  206]
  [ 290  176]]

 [[3602  123]
  [ 365   33]]]
